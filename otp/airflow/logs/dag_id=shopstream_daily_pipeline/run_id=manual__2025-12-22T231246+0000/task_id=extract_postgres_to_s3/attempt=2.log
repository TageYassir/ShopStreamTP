{"timestamp":"2025-12-22T23:18:06.001522Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-22T23:18:06.002514Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/shopstream_daily_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-22T23:18:06.266123Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.266855Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.267312Z","level":"info","event":"Current task name:extract_postgres_to_s3","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.267673Z","level":"info","event":"Dag name:shopstream_daily_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.267974Z","level":"info","event":"Extraction PostgreSQL vers S3 pour 2025-12-22","logger":"unusual_prefix_ae26fa07338e19426b897baec637b3661fba608d_shopstream_daily_pipeline","filename":"shopstream_daily_pipeline.py","lineno":72}
{"timestamp":"2025-12-22T23:18:06.285975Z","level":"error","event":"Erreur lors de l'export: python: can't open file '/opt/airflow/dags\\\\scripts\\\\export_to_s3.py': [Errno 2] No such file or directory\n","logger":"unusual_prefix_ae26fa07338e19426b897baec637b3661fba608d_shopstream_daily_pipeline","filename":"shopstream_daily_pipeline.py","lineno":76}
{"timestamp":"2025-12-22T23:18:06.286241Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":1008,"error_detail":[{"exc_type":"Exception","exc_value":"Erreur lors de l'export : python: can't open file '/opt/airflow/dags\\\\scripts\\\\export_to_s3.py': [Errno 2] No such file or directory\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":934,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1320,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":215,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":238,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":82,"name":"run"},{"filename":"/opt/airflow/dags/shopstream_daily_pipeline.py","lineno":77,"name":"extract_postgres_to_s3"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-12-22T23:18:06.305635Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.306186Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.306506Z","level":"info","event":"Task:<Task(PythonOperator): extract_postgres_to_s3>","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.307080Z","level":"info","event":"Failure caused by Erreur lors de l'export : python: can't open file '/opt/airflow/dags\\\\scripts\\\\export_to_s3.py': [Errno 2] No such file or directory","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:18:06.307537Z","level":"info","event":"","logger":"task.stdout"}

{"timestamp":"2025-12-22T23:03:14.217411Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-22T23:03:14.218636Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/shopstream_daily_pipeline.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-22T23:03:14.480264Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.480964Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.481293Z","level":"info","event":"Current task name:extract_postgres_to_s3","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.481517Z","level":"info","event":"Dag name:shopstream_daily_pipeline","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.482230Z","level":"info","event":"Extraction PostgreSQL vers S3 pour 2025-12-22","logger":"unusual_prefix_ae26fa07338e19426b897baec637b3661fba608d_shopstream_daily_pipeline","filename":"shopstream_daily_pipeline.py","lineno":111}
{"timestamp":"2025-12-22T23:03:14.486557Z","level":"error","event":"Cannot locate export script: Export script not found. Tried:\n - configured EXPORT_SCRIPT: C:\\tagemouati_yassir\\ShopStreamTP\\scripts\\export_to_s3.py\n - normalized path: C:/tagemouati_yassir/ShopStreamTP/scripts/export_to_s3.py\n - repo candidates: ['/opt/airflow/dags/scripts/export_to_s3.py', '/opt/airflow/scripts/export_to_s3.py', '/opt/airflow/dags/../scripts/export_to_s3.py']\n\nSet the correct EXPORT_SCRIPT environment variable to a path accessible inside the Airflow worker container (e.g. /opt/airflow/scripts/export_to_s3.py) and restart the scheduler.","logger":"unusual_prefix_ae26fa07338e19426b897baec637b3661fba608d_shopstream_daily_pipeline","filename":"shopstream_daily_pipeline.py","lineno":116}
{"timestamp":"2025-12-22T23:03:14.486798Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":1008,"error_detail":[{"exc_type":"FileNotFoundError","exc_value":"Export script not found. Tried:\n - configured EXPORT_SCRIPT: C:\\tagemouati_yassir\\ShopStreamTP\\scripts\\export_to_s3.py\n - normalized path: C:/tagemouati_yassir/ShopStreamTP/scripts/export_to_s3.py\n - repo candidates: ['/opt/airflow/dags/scripts/export_to_s3.py', '/opt/airflow/scripts/export_to_s3.py', '/opt/airflow/dags/../scripts/export_to_s3.py']\n\nSet the correct EXPORT_SCRIPT environment variable to a path accessible inside the Airflow worker container (e.g. /opt/airflow/scripts/export_to_s3.py) and restart the scheduler.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":934,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1320,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":215,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":238,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":82,"name":"run"},{"filename":"/opt/airflow/dags/shopstream_daily_pipeline.py","lineno":114,"name":"extract_postgres_to_s3"},{"filename":"/opt/airflow/dags/shopstream_daily_pipeline.py","lineno":106,"name":"_resolve_export_script"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-12-22T23:03:14.504671Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.510798Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.513584Z","level":"info","event":"Task:<Task(PythonOperator): extract_postgres_to_s3>","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.514181Z","level":"info","event":"Failure caused by Export script not found. Tried:","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.514572Z","level":"info","event":" - configured EXPORT_SCRIPT: C:\\tagemouati_yassir\\ShopStreamTP\\scripts\\export_to_s3.py","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.515055Z","level":"info","event":" - normalized path: C:/tagemouati_yassir/ShopStreamTP/scripts/export_to_s3.py","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.515335Z","level":"info","event":" - repo candidates: ['/opt/airflow/dags/scripts/export_to_s3.py', '/opt/airflow/scripts/export_to_s3.py', '/opt/airflow/dags/../scripts/export_to_s3.py']","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.516011Z","level":"info","event":"","logger":"task.stdout"}
{"timestamp":"2025-12-22T23:03:14.516259Z","level":"info","event":"Set the correct EXPORT_SCRIPT environment variable to a path accessible inside the Airflow worker container (e.g. /opt/airflow/scripts/export_to_s3.py) and restart the scheduler.","logger":"task.stdout"}
